{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404b9560-b429-453b-baa2-e1a09845d3b0",
   "metadata": {},
   "source": [
    "# HW5 Kaggle competition\n",
    "\n",
    "Participate this Kaggle competition: Histopathologic Cancer Detection\n",
    "https://www.kaggle.com/c/histopathologic-cancer-detection/overview\n",
    "\n",
    "After submitting the result, please submit a report and supporting material.\n",
    "You can submit as improve your results as many times as you want before the homework due.  The iterative process take time, so to get a better quality results and report, please start early. The grades are more based on the quality and depth of the analysis not just on a better kaggle score.\n",
    "\n",
    "Your report should include\n",
    "1. brief description of the problem, data (e.g. size and dimension, structure etc)\n",
    "2. Exploratory data analysis showing a few visualization, histogram, etc, and a plan of analysis. Any data cleaning procedure.\n",
    "3. You model architecture and reasoning why you believe certain architecture would be suitable for this problem\n",
    "4. results (tables, figures etc) and analysis (reasoning of why or why not something worked well, also troubleshooting and hyperparameter optimization procedure summary)\n",
    "5. your conclusion.\n",
    "\n",
    "[Deliverables- submission guide]\n",
    "1. Submit your report in moodle HW5 submission box. Your report should be in .pdf format. (you can print out your notebook if you prefer)\n",
    "Besides above report contents, your report also should include,\n",
    "Please include the url to your git (github or similar, your repo needs to be public so that I can see) in your report.\n",
    "Please include the screenshot of your leaderboard position/score.\n",
    "Importantly, your name at the top :)\n",
    "2. Upload your material such as notebook/codes/scripts to your git repository (please do not upload big files such as data)\n",
    "\n",
    "[Using online references]\n",
    "Kaggle competition is not only a tool for datascience challenges and practice, but also a great tool to learn and share skills and tips. In the kernel, there are several notebooks that people shared. Feel free to refer them, but please cite them properly. Also please keep in mind that you need to do more than what's available in those in order to get scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29d348-9b75-43ef-91a8-09fcbf30dd44",
   "metadata": {},
   "source": [
    "**The Git Repository for this project can be found at [https://github.com/seel6470/CSPB-3202-HW5](https://github.com/seel6470/CSPB-3202-HW5)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e59a3-02a2-44d3-8c03-1d58ee905429",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "*brief description of the problem, data (e.g. size and dimension, structure etc)*\n",
    "\n",
    "The Histopathologic Cancer Detection Kaggle competition (located at https://www.kaggle.com/c/histopathologic-cancer-detection/overview ) seeks to create a machine learning algorithm that can detect a cancer cell given a pathology image of tumor tissue. The problem itsel is a __binary classification problem__ with either a negative of positive prognosis. \n",
    "\n",
    "Furthermore, in the data description, it is specified that the center 32 x 32 pixel region of the image must contain at least one pixel of tumor tissue in order to be a positive prognosis.\n",
    "\n",
    "The data is contained in a file structure of the data contains two directories, `train` and `test`\n",
    "\n",
    "The `train` directory contains 220,025 tif images while the `test` directory contains 57,458 tif images.\n",
    "\n",
    "<pre>\n",
    "\n",
    "data/\n",
    "├── train/\n",
    "    ├── 0000d563d5cfafc4e68acb7c9829258a298d9b6a.tif\n",
    "    ├── 0000da768d06b879e5754c43e2298ce48726f722.tif\n",
    "    ├── 0000f8a4da4c286eee5cf1b0d2ab82f979989f7b.tif\n",
    "    ...\n",
    "├── test/\n",
    "    ├── 0000ec92553fda4ce39889f9226ace43cae3364e.tif\n",
    "    ├── 000c8db3e09f1c0f3652117cf84d78aae100e5a7.tif\n",
    "    ├── 000de14191f3bab4d2d6a7384ca0e5aa5dc0dffe.tif\n",
    "    ...\n",
    "└──\n",
    "</pre>\n",
    "\n",
    "Each file represents a color 96 x 96 image with each pixel represented as a 24 bit RGB value.\n",
    "\n",
    "The classification of all images is contained in a csv file labeled train_labels.csv with two columns, \"id\" and \"label\"\n",
    "\n",
    "The \"id\" column represents the filename (without file extension) which would be a categorical nominal data type since it represents a value with no order or ranking, while the \"label\" column represents the binary classification 0 or 1, which would also be considered categorical nominal data as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee6f69-0aea-428e-a119-70dd745a93d8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "*Exploratory data analysis showing a few visualization, histogram, etc, and a plan of analysis. Any data cleaning procedure.*\n",
    "\n",
    "It would be helpful to determine if all images have a consistent resolution, or if there may be differing image sizes. It is challenging to do so efficiently, due to the size of the data set, but creating a subset of the images and determining the resolution sizes of the images may provide more clarity.\n",
    "\n",
    "> __Note:__ Due to the size of the data set, I chose to work in a local environment, downloading all images to a local directory and running my scripts from the command line. The following code may not be executable in this notebook, but the outputs received in my local environment are shown after each code block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbf4c8-10e0-4c27-a0fe-f1cd10513f72",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('train_labels.csv', dtype=str)\n",
    "\n",
    "data['id'] = data['id'] + '.tif'  # Add file extension\n",
    "\n",
    "# Select a random subset of 256 images\n",
    "subset = data.sample(n=256, random_state=1975)\n",
    "\n",
    "train_directory = './train'\n",
    "\n",
    "# Create lists to store image widths and heights\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "# Iterate over the subset to get image dimensions\n",
    "for image_file in subset['id']:\n",
    "    image_path = os.path.join(train_directory, image_file)\n",
    "    if os.path.exists(image_path):\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            widths.append(width)\n",
    "            heights.append(height)\n",
    "    else:\n",
    "        print(f\"Image file {image_file} does not exist.\")\n",
    "\n",
    "# Plot Histogram for Widths\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(widths, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Histogram of Image Widths for 256 Random Samples')\n",
    "plt.tight_layout()\n",
    "plt.savefig('image_widths_histogram.png')\n",
    "\n",
    "# Plot Histogram for Heights\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(heights, bins=20, color='salmon', edgecolor='black')\n",
    "plt.xlabel('Height (pixels)')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Histogram of Image Heights for 256 Random Samples')\n",
    "plt.tight_layout()\n",
    "plt.savefig('image_heights_histogram.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c61341-9001-4f14-9e9b-dc3490334be9",
   "metadata": {},
   "source": [
    "![image](./images/image_heights_histogram.png)\n",
    "\n",
    "![image](./images/image_widths_histogram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63ae66-a872-4780-96fc-528640975570",
   "metadata": {},
   "source": [
    "As we can see, the resolution sizes for the random sample is exclusively 96 x 96 x 96. This is helpful, since we will need to create a way to crop the center 32 x 32 pixels given the data description on Kaggle, and the uniformity of the image size will ensure that the center will exist in the same location for all images. We can further confirm this by outputting several random images:\n",
    "\n",
    "```python\n",
    "# get 4 random images\n",
    "subset = data.sample(n=4, random_state=1975)\n",
    "\n",
    "train_directory = './train'\n",
    "\n",
    "# Create a figure to plot the images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Initialize index\n",
    "index = 1\n",
    "\n",
    "# Plot and save each image\n",
    "for image_file in subset['id']:\n",
    "    image_path = os.path.join(train_directory, image_file)\n",
    "    if os.path.exists(image_path):\n",
    "        with Image.open(image_path) as img:\n",
    "            plt.subplot(2, 2, index)  # Use index to determine subplot position\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'Image {index}')\n",
    "            plt.axis('off')  # Turn off axis\n",
    "            index += 1\n",
    "    else:\n",
    "        print(f\"Image file {image_file} does not exist.\")\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd959071-01a1-47fd-9add-071582e730f6",
   "metadata": {},
   "source": [
    "![image](./images/sample_images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529293e0-baf3-477b-94da-cdc3a3c9ffc8",
   "metadata": {},
   "source": [
    "Additionally, it would be helpful to know what distribution of labels we have in our training data. We would hope to see an equal amount of binary classifications to avoid bias in our model, however it would be beneficial to understand our data if the distribution is otherwise.\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('train_labels.csv', dtype=str)\n",
    "\n",
    "label_counts = data['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', colors=['skyblue', 'salmon'])\n",
    "plt.title('Distribution of Binary Labels (0 and 1)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show the pie chart\n",
    "plt.savefig('binary_labels_pie_chart.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eeb882-6b69-4e9c-8d4f-1dc31e933d32",
   "metadata": {},
   "source": [
    "![image](./images/binary_labels_pie_chart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9462f338-2fd9-49bc-8ee0-dd171eac7390",
   "metadata": {},
   "source": [
    "We can see that we have more negative than positive prognosis images in our training set. Given the large size of the data set, this should not cause too much of an issue. If there was a higher class imbalance (say 90/10) there would be cause for concern, however we still want to make sure we watch out to see if the model learns that it is more accurate to predict 0 than 1 given the current imbalance. Because of this, we may seek to use other metrics than accuracy, such as the area under the ROC curve when evaluating the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ab6cd8-2140-4c87-b038-ea592f888666",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "*You model architecture and reasoning why you believe certain architecture would be suitable for this problem*\n",
    "\n",
    "I have had some experience with creating classification models using Tensorflow and Keras, and additionally decided to use a pre-trained convolutional neural network model, or CNN with additional custom layers. To begin, we will need to import all of the libraries that will be useful:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import os\n",
    "```\n",
    "\n",
    "Next, we will need to load our data in a format that is conducive to the Tensorflow Keras models using Pandas:\n",
    "\n",
    "```python\n",
    " Load the data\n",
    "data = pd.read_csv('train_labels.csv', dtype=str)\n",
    "\n",
    "data['id'] = data['id'] + '.tif'  # add tif to each filename\n",
    "```\n",
    "\n",
    "Next, we will split the train and test data and create Pandas dataframes from the :\n",
    "\n",
    "```python\n",
    "filenames = data['id'].values\n",
    "labels = data['label'].values\n",
    "\n",
    "train_filenames, val_filenames, train_labels, val_labels = train_test_split(filenames, labels, test_size=0.2, random_state=75)\n",
    "\n",
    "train_df = pd.DataFrame({'id': train_filenames, 'label': train_labels})\n",
    "val_df = pd.DataFrame({'id': val_filenames, 'label': val_labels})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd29b8-a32e-42bb-bb2e-4947110bd8a3",
   "metadata": {},
   "source": [
    "Now we will need to create a dataset that can be used in a Tensorflow Keras model. I struggled quite a bit with this step, but referencing other projects posted on the Kaggle site assisted greatly. [Alexander Y.'s Kaggle page](https://www.kaggle.com/code/alexanderyyy/fastai2-albumentations-focalloss-balancedaccuracy) was very handy in particular (Alexander Y., 2022, Histopathologic Cancer Detection, retrieved from FastAI2, Albumentations, FocalLoss, BalancedAccuracy)\n",
    "\n",
    "Using the tensorflow.keras.preprocessing.image.ImageDataGenerator came in handy as it greatly simplified the process. Note that we are normalizing the RGB values as well as creating the target size of 32 x 32 pixels.\n",
    "\n",
    "```python\n",
    "# create image data generators, normalizing RGB values\n",
    "train_generator = ImageDataGenerator(rescale=1/255)\n",
    "validation_generator = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_dataset = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=train_directory,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    target_size=(32, 32)\n",
    ")\n",
    "\n",
    "val_dataset = validation_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=train_directory,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical',\n",
    "    target_size=(32, 32)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded55bd-fe1d-4c04-ac71-c1acc91612fe",
   "metadata": {},
   "source": [
    "#### Initial Model\n",
    "\n",
    "Initially, I began with a simple CNN model that used the EfficientNetB0 base model with some simple additional convolutional layers:\n",
    "```python\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "cnn = base_model.output\n",
    "cnn = GlobalAveragePooling2D()(cnn)\n",
    "cnn = Dense(1024, activation='relu')(cnn)\n",
    "cnn = Dropout(0.5)(cnn)\n",
    "cnn = Dense(512, activation='relu')(cnn)\n",
    "cnn = Dropout(0.5)(cnn)\n",
    "predictions = Dense(1, activation='sigmoid')(cnn)\n",
    "```\n",
    "\n",
    "The Global Average Pooling layer reduces the spatial dimensions and flattens the data to a 1D array, the Dense layers are fully connected layers utilizing the ReLU activation function, and the dropout layers removes half of the neurons after the fully activated layers to prevent overfitting.\n",
    "\n",
    "I then compiled the model fit the model using the Adam optimizer with an initial learning rate of 0.001 and the categorical crossentropy loss function using both accuracy and the area under the ROC curve (given the distribution of classifications found previously). I then fit this model using 40 epochs.\n",
    "\n",
    "```python\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "\n",
    "# Train the model\n",
    "cnn.fit(\n",
    "    x = train_dataset, \n",
    "    steps_per_epoch = len(train_dataset),\n",
    "    epochs = 40,\n",
    "    validation_data = val_dataset, \n",
    "    validation_steps = len(val_df), \n",
    "    verbose = 1\n",
    ")\n",
    "```\n",
    "\n",
    "Finally, I used the model to predict the values in the test data and saved the values to a csv to submit:\n",
    "\n",
    "```python\n",
    "# Create test dataset\n",
    "test_filenames = [f for f in os.listdir(test_directory)]\n",
    "\n",
    "test_labels = np.zeros(len(test_filenames), dtype=np.int64)\n",
    "test_df = pd.DataFrame({'id': test_filenames, 'label': test_labels})\n",
    "print(test_df.head())\n",
    "\n",
    "test_dataset = validation_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_directory,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(32, 32)\n",
    ")\n",
    "\n",
    "predictions = cnn.predict(test_dataset)\n",
    "# predictions are presented as a list of tuples with probabilities for each category\n",
    "# e.g. [0.5671,0.4329]\n",
    "# the actual category will be equal to the index of the maximum element in the tuplepredicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "# Create a DataFrame with the IDs and predicted labels\n",
    "submission = pd.DataFrame({'id': test_filenames, 'label': predicted_labels})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission.to_csv('final_submission.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788471c2-56e6-474d-8b46-2de3fb673eeb",
   "metadata": {},
   "source": [
    "Unfortunately, this initial model did not perform very well, with a Kaggle score of only 0.5\n",
    "\n",
    "Because of this, I went back to the drawing board to make some improvements.\n",
    "\n",
    "### Second Model\n",
    "\n",
    "I realized that incorporating 2D convolutional layers would be most appropriate as they are meant for feature extraction from 2D images by using filters over the 2 dimensional pixel area. Doing additional research, I realized MaxPooling would be most appropriate with Conv2D layers, as GlobalMaxPooling operates on the entire feature map and is better used at the end of the neural network. Additional, I decided to repeat these convolutional layers with more features each time, initially with 16, then 64, then 128, before performing the final fully connected layers at the end.\n",
    "\n",
    "```python\n",
    "# Load pre-trained EfficientNetB0 model + higher level layers\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "cnn = Sequential([\n",
    "    # 16 filters capture low level features (e.g. edges)\n",
    "    Conv2D(16, (3,3), activation = 'relu', padding = 'same', input_shape=(32,32,3)),\n",
    "    Conv2D(16, (3,3), activation = 'relu', padding = 'same'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    # 64 filters capture more complex features (general shapes)\n",
    "    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # 128 filters capture high-level abstract features\n",
    "    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n",
    "    Conv2D(128, (3,3), activation = 'relu', padding = 'same'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    # final fully connected layers\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "```\n",
    "\n",
    "Additionally, I decided to train the model for 90 epochs as opposed to the initial 40 in the hopes of gaining further fine tuned adjustments to the model. \n",
    "\n",
    "```python\n",
    "model = cnn.fit(\n",
    "    x = train_dataset, \n",
    "    steps_per_epoch = len(train_dataset),\n",
    "    epochs = 90,\n",
    "    validation_data = val_dataset, \n",
    "    validation_steps = len(val_df), \n",
    "    verbose = 0\n",
    ")\n",
    "```\n",
    "\n",
    "I also captured the history and plotted the loss, accuracy and area under the ROC curve of both the training and validation data. \n",
    "\n",
    "```python\n",
    "history = model.history\n",
    "\n",
    "epoch_range = range(1, len(history['loss'])+1)\n",
    "\n",
    "plt.figure(figsize=[14,4])\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(epoch_range, history['loss'], label='Training')\n",
    "plt.plot(epoch_range, history['val_loss'], label='Validation')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(epoch_range, history['accuracy'], label='Training')\n",
    "plt.plot(epoch_range, history['val_accuracy'], label='Validation')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(epoch_range, history['auc'], label='Training')\n",
    "plt.plot(epoch_range, history['val_auc'], label='Validation')\n",
    "plt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e98a94-f560-42f9-8d15-5d258783d0b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results\n",
    "\n",
    "*results (tables, figures etc) and analysis (reasoning of why or why not something worked well, also troubleshooting and hyperparameter optimization procedure summary)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d756a3b-5e0a-489b-9e15-2fd9157d0dca",
   "metadata": {},
   "source": [
    "![image](./images/model_fitting_history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111772b-1f42-4f9f-987d-854ac559d43e",
   "metadata": {},
   "source": [
    "As we can see from the captured loss, accuracy and AUC values, the loss steadily decreases while the accuracy and AUC steadily increase. This is indicating that it is, in fact, learning and distinguishing between classes until the model converges.\n",
    "\n",
    "The validation data shows wild fluctuations, which may indicate possible overfitting resulting in less accurate performance on the validation.\n",
    "\n",
    "Despite this, when submitting scores, I was able to receive a public score of 0.8110 and a private score of 0.7617"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77ba704-c3ef-4c7e-88b2-8b3d9ee18aa7",
   "metadata": {},
   "source": [
    "## Final Submission Screenshot:\n",
    "\n",
    "![image](./images/Screenshot%202024-08-01%20151900.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d859b-4219-4051-957a-66da06f68b45",
   "metadata": {},
   "source": [
    "Although there is much room for improvement, the Kaggle score and training values indicate that the model architecture was able to do exactly what it was meant for, finding and capturing important features that allowed it to predict, to some degree of accuracy, the binary classifications of these images.\n",
    "\n",
    "Given more time, I would like to make further improvements, such as fine-tuning the learning rates. It could also be beneficial to fit the model in three phases, using decreasing learning rates between each phase to produce faster convergence.\n",
    "\n",
    "Another aspect I would like to explore further is the fact that the center 32 pixels are what indicates a positive or negative classification:\n",
    "\n",
    ">A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label.\n",
    "\n",
    "I realize that using `target_size = (32,32)` in the image data generator simply fits the entire image to a 32 x 32 size. It would be beneficial to create a preprocessing function that could be used with the `ImageDataGenerator` in the `preprocessor` parameter that crops the center 32 x 32 pixels that could possibly produce better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56211e8c-d4ee-4332-bbde-92efd25eaf6a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Working with this large amount of data proved challenging, as many times I would begin to fit my model over the training data only for it to crash after several hours. I was able to use the Tensorflow with GPU to speed this up, but simply getting a working model took a majority of my time with this project. With the help of suggestions and help posted on Piazza as well as additional Notebooks posted on Piazza, I was able to get a working model that was not only able to run successfully, but also produce results that were compelling. \n",
    "\n",
    "A 0.8110 public score means that the architecture and model fitting was able to interpret a variety of features in the test data, despite indications of overfitting in the captured history during learning. This was in large part thanks to the inclusion of the convolutional 2D layers in three phases, using increasing filter sizes each time. Because of this, the model was able to learn features from the most general to more specific feature representations in the image.\n",
    "\n",
    "All in all, I feel like I have a better understanding of Machine Learning modeling after this project than I did before, and for that reason I believe this to be a successful implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
