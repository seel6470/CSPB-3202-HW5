{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d29d348-9b75-43ef-91a8-09fcbf30dd44",
   "metadata": {},
   "source": [
    "**The Git Repository for this project can be found at [https://github.com/seel6470/CSPB-3202-HW5](https://github.com/seel6470/CSPB-3202-HW5)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e59a3-02a2-44d3-8c03-1d58ee905429",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "*brief description of the problem, data (e.g. size and dimension, structure etc)*\n",
    "\n",
    "The Histopathologic Cancer Detection Kaggle competition (located at https://www.kaggle.com/c/histopathologic-cancer-detection/overview ) seeks to create a machine learning algorithm that can detect a cancer cell given a pathology image of tumor tissue. The problem itsel is a __binary classification problem__ with either a negative of positive prognosis. \n",
    "\n",
    "Furthermore, in the data description, it is specified that the center 32 x 32 pixel region of the image must contain at least one pixel of tumor tissue in order to be a positive prognosis.\n",
    "\n",
    "The data is contained in a file structure of the data contains two directories, `train` and `test`\n",
    "\n",
    "The `train` directory contains 220,025 tif images while the `test` directory contains 57,458 tif images.\n",
    "\n",
    "<pre>\n",
    "\n",
    "data/\n",
    "├── train/\n",
    "    ├── 0000d563d5cfafc4e68acb7c9829258a298d9b6a.tif\n",
    "    ├── 0000da768d06b879e5754c43e2298ce48726f722.tif\n",
    "    ├── 0000f8a4da4c286eee5cf1b0d2ab82f979989f7b.tif\n",
    "    ...\n",
    "├── test/\n",
    "    ├── 0000ec92553fda4ce39889f9226ace43cae3364e.tif\n",
    "    ├── 000c8db3e09f1c0f3652117cf84d78aae100e5a7.tif\n",
    "    ├── 000de14191f3bab4d2d6a7384ca0e5aa5dc0dffe.tif\n",
    "    ...\n",
    "└──\n",
    "</pre>\n",
    "\n",
    "Each file represents a color 96 x 96 image with each pixel represented as a 24 bit RGB value.\n",
    "\n",
    "The classification of all images is contained in a csv file labeled train_labels.csv with two columns, \"id\" and \"label\"\n",
    "\n",
    "The \"id\" column represents the filename (without file extension) which would be a categorical nominal data type since it represents a value with no order or ranking, while the \"label\" column represents the binary classification 0 or 1, which would also be considered categorical nominal data as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee6f69-0aea-428e-a119-70dd745a93d8",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "*Exploratory data analysis showing a few visualization, histogram, etc, and a plan of analysis. Any data cleaning procedure.*\n",
    "\n",
    "It would be helpful to determine if all images have a consistent resolution, or if there may be differing image sizes. It is challenging to do so efficiently, due to the size of the data set, but creating a subset of the images and determining the resolution sizes of the images may provide more clarity.\n",
    "\n",
    "> __Note:__ Due to the size of the data set, I chose to work in a local environment, downloading all images to a local directory and running my scripts from the command line. The following code may not be executable in this notebook, but the python scripts are included in the GitHub repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbf4c8-10e0-4c27-a0fe-f1cd10513f72",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('train_labels.csv', dtype=str)\n",
    "\n",
    "data['id'] = data['id'] + '.tif'  # Add file extension\n",
    "\n",
    "# Select a random subset of 256 images\n",
    "subset = data.sample(n=256, random_state=1975)\n",
    "\n",
    "train_directory = './train'\n",
    "\n",
    "# Create lists to store image widths and heights\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "# Iterate over the subset to get image dimensions\n",
    "for image_file in subset['id']:\n",
    "    image_path = os.path.join(train_directory, image_file)\n",
    "    if os.path.exists(image_path):\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            widths.append(width)\n",
    "            heights.append(height)\n",
    "    else:\n",
    "        print(f\"Image file {image_file} does not exist.\")\n",
    "\n",
    "# Plot Histogram for Widths\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(widths, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Histogram of Image Widths for 256 Random Samples')\n",
    "plt.tight_layout()\n",
    "plt.savefig('image_widths_histogram.png')\n",
    "\n",
    "# Plot Histogram for Heights\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(heights, bins=20, color='salmon', edgecolor='black')\n",
    "plt.xlabel('Height (pixels)')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Histogram of Image Heights for 256 Random Samples')\n",
    "plt.tight_layout()\n",
    "plt.savefig('image_heights_histogram.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c61341-9001-4f14-9e9b-dc3490334be9",
   "metadata": {},
   "source": [
    "![image](images/image_heights_histogram.png)\n",
    "\n",
    "![image](images/image_widths_histogram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63ae66-a872-4780-96fc-528640975570",
   "metadata": {},
   "source": [
    "As we can see, the resolution sizes for the random sample is exclusively 96 x 96 x 96. This is helpful, since we will need to create a way to crop the center 32 x 32 pixels given the data description on Kaggle, and the uniformity of the image size will ensure that the center will exist in the same location for all images. We can further confirm this by outputting several random images:\n",
    "\n",
    "```python\n",
    "# get 4 random images\n",
    "subset = data.sample(n=4, random_state=1975)\n",
    "\n",
    "train_directory = './train'\n",
    "\n",
    "# Create a figure to plot the images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Initialize index\n",
    "index = 1\n",
    "\n",
    "# Plot and save each image\n",
    "for image_file in subset['id']:\n",
    "    image_path = os.path.join(train_directory, image_file)\n",
    "    if os.path.exists(image_path):\n",
    "        with Image.open(image_path) as img:\n",
    "            plt.subplot(2, 2, index)  # Use index to determine subplot position\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'Image {index}')\n",
    "            plt.axis('off')  # Turn off axis\n",
    "            index += 1\n",
    "    else:\n",
    "        print(f\"Image file {image_file} does not exist.\")\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_images.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd959071-01a1-47fd-9add-071582e730f6",
   "metadata": {},
   "source": [
    "![image](images/sample_images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529293e0-baf3-477b-94da-cdc3a3c9ffc8",
   "metadata": {},
   "source": [
    "Additionally, it would be helpful to know what distribution of labels we have in our training data. We would hope to see an equal amount of binary classifications to avoid bias in our model, however it would be beneficial to understand our data if the distribution is otherwise.\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('train_labels.csv', dtype=str)\n",
    "\n",
    "label_counts = data['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', colors=['skyblue', 'salmon'])\n",
    "plt.title('Distribution of Binary Labels (0 and 1)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show the pie chart\n",
    "plt.savefig('binary_labels_pie_chart.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eeb882-6b69-4e9c-8d4f-1dc31e933d32",
   "metadata": {},
   "source": [
    "![image](images/binary_labels_pie_chart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9462f338-2fd9-49bc-8ee0-dd171eac7390",
   "metadata": {},
   "source": [
    "We can see that we have more negative than positive prognosis images in our training set. Given the large size of the data set, this should not cause too much of an issue. If there was a higher class imbalance (say 90/10) there would be cause for concern, however we still want to make sure we watch out to see if the model learns that it is more accurate to predict 0 than 1 given the current imbalance. Because of this, we may seek to use other metrics than accuracy, such as the area under the ROC curve when evaluating the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ab6cd8-2140-4c87-b038-ea592f888666",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "I have had some experience with creating classification models using Tensorflow and Keras, and additionally decided to use a pre-trained convolutional neural network model, or CNN with additional custom layers. To begin, we will need to import all of the libraries that will be useful:\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "```\n",
    "\n",
    "Next, we will need to load our data in a format that is conducive to the Tensorflow Keras models using Pandas:\n",
    "\n",
    "```python\n",
    " Load the data\n",
    "data = pd.read_csv('train_labels.csv', dtype=str)\n",
    "\n",
    "data['id'] = data['id'] + '.tif'  # add tif to each filename\n",
    "```\n",
    "\n",
    "Next, we will split the train and test data and create Pandas dataframes from the :\n",
    "\n",
    "```python\n",
    "filenames = data['id'].values\n",
    "labels = data['label'].values\n",
    "\n",
    "train_filenames, val_filenames, train_labels, val_labels = train_test_split(filenames, labels, test_size=0.2, random_state=75)\n",
    "\n",
    "train_df = pd.DataFrame({'id': train_filenames, 'label': train_labels})\n",
    "val_df = pd.DataFrame({'id': val_filenames, 'label': val_labels})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd29b8-a32e-42bb-bb2e-4947110bd8a3",
   "metadata": {},
   "source": [
    "Now we will need to create a dataset that can be used in a Tensorflow Keras model. I struggled quite a bit with this step, but referencing other projects posted on the Kaggle site assisted greatly. [Kern T.'s Kaggle page](https://kaggle.com/code/taylorkern/histopathologic-cancer-detection) was very handy in particular (Kern, 2022)\n",
    "\n",
    "Using the tensorflow.keras.preprocessing.image.ImageDataGenerator came in handy as it greatly simplified the process. Note that we are normalizing the RGB values as well as creating the target size of 32 x 32 pixels.\n",
    "\n",
    "```python\n",
    "# create image data generators, normalizing RGB values\n",
    "train_generator = ImageDataGenerator(rescale=1/255)\n",
    "validation_generator = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_dataset = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=train_directory,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical',\n",
    "    target_size=(32, 32)\n",
    ")\n",
    "\n",
    "val_dataset = validation_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=train_directory,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical',\n",
    "    target_size=(32, 32)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded55bd-fe1d-4c04-ac71-c1acc91612fe",
   "metadata": {},
   "source": [
    "## Initial Model\n",
    "\n",
    "Initially, I began with a simple CNN model that used the EfficientNetB0 base model with some simple additional convolutional layers:\n",
    "```python\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "cnn = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(2, activation='softmax'),\n",
    "    Dropout(0.5)\n",
    "])\n",
    "```\n",
    "\n",
    "The Global Average Pooling layer reduces the spatial dimensions and flattens the data to a 1D array, the Dense layers are fully connected layers utilizing the ReLU activation function, and the dropout layers removes half of the neurons after the fully activated layers to prevent overfitting.\n",
    "\n",
    "I then compiled the model fit the model using the Adam optimizer with an initial learning rate of 0.001 and the categorical crossentropy loss function using both accuracy and the area under the ROC curve (given the distribution of classifications found previously). I then fit this model using 40 epochs.\n",
    "\n",
    "```python\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "\n",
    "model = cnn.fit(\n",
    "    x = train_dataset, \n",
    "    steps_per_epoch = len(train_dataset),\n",
    "    epochs = 40,\n",
    "    validation_data = val_dataset, \n",
    "    validation_steps = len(val_dataset), \n",
    "    verbose = 1\n",
    ")\n",
    "```\n",
    "\n",
    "We then capture the loss, accuracy, and Area under the AUC curve for the training and validation date:\n",
    "\n",
    "```python\n",
    "history = model.history\n",
    "\n",
    "epoch_range = range(1, len(history['loss'])+1)\n",
    "\n",
    "plt.figure(figsize=[14,4])\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(epoch_range, history['loss'], label='Training')\n",
    "plt.plot(epoch_range, history['val_loss'], label='Validation')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(epoch_range, history['accuracy'], label='Training')\n",
    "plt.plot(epoch_range, history['val_accuracy'], label='Validation')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(epoch_range, history['auc'], label='Training')\n",
    "plt.plot(epoch_range, history['val_auc'], label='Validation')\n",
    "plt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs.png')\n",
    "```\n",
    "\n",
    "Finally, I used the model to predict the values in the test data and saved the values to a csv to submit:\n",
    "\n",
    "```python\n",
    "test_filenames = [f for f in os.listdir(test_directory)]\n",
    "\n",
    "test_labels = np.zeros(len(test_filenames), dtype=np.int64)\n",
    "test_df = pd.DataFrame({'id': test_filenames, 'label': test_labels})\n",
    "print(test_df.head())\n",
    "\n",
    "test_dataset = validation_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=test_directory,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    batch_size=batch_size,\n",
    "    seed=1,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(32, 32)\n",
    ")\n",
    "\n",
    "predictions = cnn.predict(test_dataset)\n",
    "# predictions are presented as a list of tuples with probabilities for each category\n",
    "# e.g. [0.5671,0.4329]\n",
    "# the actual category will be equal to the index of the maximum element in the tuplepredicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "# Create a DataFrame with the IDs and predicted labels\n",
    "submission = pd.DataFrame({'id': test_filenames, 'label': predicted_labels})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission.to_csv('final_submission.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaecf5f5-3d44-45a1-afab-231e007c8601",
   "metadata": {},
   "source": [
    "![image](images/first_graphs.png)\n",
    "\n",
    "Unfortunately, this initial model did not perform very well, with a Kaggle score of only 0.5 with a static prediction of 0 for all test images and NaN values for the loss for the train and validation data during training. Upon closer inspection, I realized the dropout layer after the final layer would cause significant issues, as droppout should only be used prior to the final fully connected layer. Otherwise, 50% of the data wijll be set to a class of 0. This does not indicate a successful model, and further work must be done to create a fully working model architecture suitable \n",
    "\n",
    "Because of this, I went back to the drawing board to make some improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755b093-c39c-4abf-b805-39f0172e01b3",
   "metadata": {},
   "source": [
    "## Second Model\n",
    "\n",
    "Firstly, let's remove the final dropout to correct the error from the first model. Additionally, I realized that incorporating 2D convolutional layers would be most appropriate as they are meant for feature extraction from 2D images by using filters over the 2 dimensional pixel area. Doing additional research, I realized MaxPooling would be most appropriate with Conv2D layers, as GlobalMaxPooling operates on the entire feature map and is better used at the end of the neural network. Additionally, I decided to repeat these convolutional layers twice using more features the second time, initially with 16, then 128, before performing the final fully connected layers at the end. This should help the model capture the low-level features initially and then capturing high-level abstract features when using a higher feature level. To gain additional insight, I also increased the number of epochs to 90.\n",
    "\n",
    "```python\n",
    "# Load pre-trained EfficientNetB0 model + higher level layers\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "cnn = Sequential([\n",
    "    base_model,\n",
    "\n",
    "    # 16 filters capture low level features (e.g. edges)\n",
    "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2,2, padding='same'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    # 128 filters capture high-level abstract features\n",
    "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2,2, padding='same'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    GlobalAveragePooling2D(),\n",
    "    Flatten(),\n",
    "    \n",
    "    # final fully connected layers\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "```\n",
    "\n",
    "I also decided to train the model for 90 epochs as opposed to the initial 40 in the hopes of gaining further fine tuned adjustments to the model. \n",
    "\n",
    "```python\n",
    "model = cnn.fit(\n",
    "    x = train_dataset, \n",
    "    steps_per_epoch = len(train_dataset),\n",
    "    epochs = 90,\n",
    "    validation_data = val_dataset, \n",
    "    validation_steps = len(val_dataset), \n",
    "    verbose = 0\n",
    ")\n",
    "```\n",
    "\n",
    "And captured the graphs for this submission as well:\n",
    "\n",
    "![image](images/second_graphs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bdf96c-b4a4-45fe-9484-6164dd2c9304",
   "metadata": {},
   "source": [
    " As we can see from the graphs above, the accuracy and AUC values for the training data increase and flatten close to 1 as would be expected from a working model. The validation data, however, shows significant instability with a massive peak in the loss and valleys along the accuracy and AUC values, the latter of which never increase to any significant value that would indicate that it is going to work with the test dataset. This indicates that the model is overfitting to the training data and is not making valid insights into the images themselves. The output for the submission file also shows that all predictions for the test data are all zeros. Looking at the class distribution of the training data, it could possibly be biased towards the class with the highest percentage in the training data, choosing 0 every time.\n",
    "\n",
    "Because of this, I chose to take one more shot to make some improvements to create a model that gathers some applicable insights into classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd58be4-442d-4cd8-ba6b-3370b2ff1456",
   "metadata": {},
   "source": [
    "## Third Model\n",
    "\n",
    "Upon researching what could be causing the model to perform poorly over the validation data, I realized that a high learning rate can cause the model to make large updates to the weights, causing instability. To counteract this, I will create a learning rate scheduler to reduce the learning rate for different thresholds of epochs. This should allow the model to create fine-tuned adjustments with higher iterations.\n",
    "\n",
    "I also looked over the original problem description and noticed the following passage:\n",
    "\n",
    ">A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label.\n",
    "\n",
    "I realize that using `target_size = (32,32)` in the image data generator simply reduces the entire image size to a 32 x 32 pixel resolution. It would be beneficial to create a preprocessing function that could be used with the `ImageDataGenerator` in the `preprocessor` parameter that crops the center 32 x 32 pixels. With these two improvements, I am hoping the model will be more functional and provide a significant Kaggle score.\n",
    "\n",
    "The following is the preprocessing function I will use to crop the center 32 x 32 pixels:\n",
    "\n",
    "```python\n",
    "# Define a preprocessing function to crop the center 32x32 pixels\n",
    "def center_crop(image):\n",
    "    center = (image.shape[0] // 2, image.shape[1] // 2)\n",
    "    half_crop_size = img_width // 2\n",
    "    cropped_image = image[center[0] - half_crop_size:center[0] + half_crop_size, center[1] - half_crop_size:center[1] + half_crop_size]\n",
    "    return cropped_image\n",
    "\n",
    "# create image data generators, normalizing RGB values\n",
    "train_generator = ImageDataGenerator(rescale=1/255, preprocessing_function = center_crop)\n",
    "validation_generator = ImageDataGenerator(rescale=1/255, preprocessing_function = center_crop)\n",
    "```\n",
    "\n",
    "Additionally, we will train the model using a learning rate scheduler to decrease the learning rate as the epochs go on. We can do this by simply defining a scheduler function and create a callback through tf.keras.callbacks.LearningRateScheduler and pass it to the fit paramaters:\n",
    "\n",
    "```python\n",
    "# Learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 50:\n",
    "        return lr\n",
    "    elif epoch < 80:\n",
    "        return lr * 0.5\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# Train the model\n",
    "model = cnn.fit(\n",
    "    x = train_dataset, \n",
    "    steps_per_epoch = len(train_dataset),\n",
    "    epochs = 100,\n",
    "    validation_data = val_dataset, \n",
    "    validation_steps = len(val_dataset), \n",
    "    verbose = 1,\n",
    "    callbacks = [lr_callback]\n",
    ")\n",
    "```\n",
    "We will start with a learning rate of 0.001, dividing it by 2 at 50 epochs to a learning rate of 0.0005, and finally multiplying it by 0.1 to get a learning rate of 0.00005 for the final 20 epochs.  This should help the model to converge better and hopefully create more stability.\n",
    "\n",
    "As usual, we plot the loss, accuracy and AUC values of the training and validation:\n",
    "\n",
    "![image](images/third_graphs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c3c98-063e-44dc-9862-99e4d08f8a29",
   "metadata": {},
   "source": [
    "We see a similar spike in the loss values initially, which skews our data, however the values do reduce over time.\n",
    "\n",
    "The Accuracy and AUC values for the training data rises logarithmically and converges close to 1 as previously, however there is a noticeable change in the validation trends that occurs somewhat near the first reduction in the learning rate at 50 epochs. The validation data also flattens pit close to 0.9, which is what would be much more expected with a working model. Looking at the submission data, there are a combination of both 1's and 0's, which means the improvements were likely successful.\n",
    "\n",
    "Submitting these classifications to the Kaggle competition resulted in a private score of 0.7776 and a public score of 0.8209. This means our architecture for the model was successful in allowing the model to make significant correlations into the classification of the image data. The full breakdown of scores for all three models can be seen below:\n",
    "\n",
    "![image](images/kaggle_scores.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e98a94-f560-42f9-8d15-5d258783d0b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results\n",
    "\n",
    "*results (tables, figures etc) and analysis (reasoning of why or why not something worked well, also troubleshooting and hyperparameter optimization procedure summary)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111772b-1f42-4f9f-987d-854ac559d43e",
   "metadata": {},
   "source": [
    "Once again, here are the graphs of loss, accuracy, and AUC for the three models:\n",
    "\n",
    "## First Model\n",
    "\n",
    "![image](images/first_graphs.png)\n",
    "No meaningful or significant data, indicating serious problems with the model architecture. __Public Kaggle Score:__ 0.5000\n",
    "\n",
    "## Second Model\n",
    "- *Removing final dropout layer after dense layer (made in error)*\n",
    "- *adding Conv2d layers*\n",
    "- *duplicating architecture with increasing features second time around*\n",
    "\n",
    "![image](images/second_graphs.png)\n",
    "Training accuracy and AUC indicates model is learning, but validation values indicate model instability. __Public Kaggle Score:__ 0.5000\n",
    "\n",
    "## Third Model\n",
    "- *Cropping center 32 x 32 pixels instead of size reduction to 32 x 32 pixels*\n",
    "- *Create learning rate scheduler*\n",
    "\n",
    "![image](images/third_graphs.png)\n",
    "Training accuracy and AUC flatten out near 1.0, indicating a working model and validation values increase significantly near 50 epochs with learning rate reduction, indicating decent performance over validation data. __Public Kaggle Score:__ 0.8209"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56211e8c-d4ee-4332-bbde-92efd25eaf6a",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Working with this large amount of data proved challenging, as many times I would begin to fit my model over the training data only for it to crash after several hours. I was able to use the Tensorflow with GPU to speed this up, but working with the number of epochs I chose for the architecture cost considerable processing time that was exceeding 7 hours and would still be processing in the morning after I initiated the script the night before. Simply getting a working model took a majority of my time with this project, and even the first model was a significant and noteworthy milestone.\n",
    "\n",
    "A 0.8209 public score means that the architecture and model fitting was able to interpret a variety of features in the test data, overcoming issues with overfitting and instability found in the previous two models.\n",
    "\n",
    "All in all, I feel like I have a better understanding of Machine Learning modeling after this project than I did before, and for that reason, as well as the final Kaggle score, I believe this to be a successful implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dd5c7-5713-48fd-bd6b-40890cb7516a",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Cukierski, W. (2018). Histopathologic Cancer Detection. Kaggle. https://kaggle.com/competitions/histopathologic-cancer-detection\n",
    "\n",
    "Kern, T. (2022). PyTorch CNN: Histopathologic Cancer Detection. Kaggle. https://kaggle.com/code/taylorkern/histopathologic-cancer-detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
